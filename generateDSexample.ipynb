{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using generateDS on REG AB II\n",
    "2020-09-07\n",
    "\n",
    "The script generateDS.py generates Python code from an xsd. This code can be a good starter to use instead of the xml library for parsing xml, to take advantage of all the info in the xsd. We'll use the [generateDS](https://www.davekuhlman.org/generateDS.html) to read an XML Auto Loan file [Version 1,8](https://www.sec.gov/info/edgar/specifications/absxml.htm), since that's the xml I am wrestling with. \n",
    "\n",
    "After installing (see instructions at link), the CL used is below. \n",
    "- generateDS -o \"autoLoan.py\" -s \"autoSub.py\" eis_ABS_AutoLoanAssetData.xsd\n",
    "Conveniently, the script stores the CL in the generated code, so you can always check to see what you ran. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from collections import OrderedDict\n",
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "\n",
    "import autoSub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n",
    "All the files but the xml used here are in the repo. Names below. The xml file is too big to store on gh and we'll have to pull a copy over from Edgar. There is a copy as well on S3 in case Edgar reorgs this someplace else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "XSDN = \"eis_ABS_AutoLoanAssetData.xsd\" # autoLoan schema (from Edgar)\n",
    "LWBN = \"dtypes.xls\" # xls layout (retyped)\n",
    "\n",
    "GC1N = \"genAutoLoan.py\" # geneted code file\n",
    "GC2N = \"genAutoSub.py\" # additional generated code file\n",
    "INFN = \"20200706.AfsSensub.xml\" # one submission for a month for one SPE\n",
    "\n",
    "# S3 copy of this file in case Edgar reorrgs\n",
    "# RABD = \"https://datadeloro0tutorials.s3-us-west-2.amazonaws.com/regAB\" # directory\n",
    "# INFP = \"/\".join((RABD, \"xml\", INFN))\n",
    "\n",
    "EDGR = \"https://www.sec.gov/Archives/edgar/data\"\n",
    "INFP = \"/\".join((EDGR, \"1347185/000134718520000016/exh1024080052020.xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabled version of layout\n",
    "I hand copied the PDF layout from [Edgar](https://www.sec.gov/info/edgar/specifications/absxml.htm) and made some notes that will help with using the data later. Browse if interested, but we can read directly into Pandas! Here, we are just using the list of fieldnames to keel things in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmtR = pd.read_excel(LWBN).set_index(\"index\")\n",
    "fmtR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fieldName</th>\n",
       "      <th>dType</th>\n",
       "      <th>maxLength</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assetTypeNumber</td>\n",
       "      <td>str</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assetNumber</td>\n",
       "      <td>str</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reportingPeriodBeginningDate</td>\n",
       "      <td>Mm-dd-yyyy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reportingPeriodEndingDate</td>\n",
       "      <td>Mm-dd-yyyy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>originatorName</td>\n",
       "      <td>str</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fieldName       dType maxLength encoding\n",
       "index                                                             \n",
       "1                   assetTypeNumber         str       100      NaN\n",
       "2                       assetNumber         str        25      NaN\n",
       "3      reportingPeriodBeginningDate  Mm-dd-yyyy       NaN      NaN\n",
       "4         reportingPeriodEndingDate  Mm-dd-yyyy       NaN      NaN\n",
       "5                    originatorName         str        50      NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmtR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate code with generateDS\n",
    "Assumed that that has been installed somewhere on path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('generateDS -o \"%s\" -s \"%s\" eis_ABS_AutoLoanAssetData.xsd' %(GC1N, GC2N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minor edit to one of the generated files\n",
    "The \"???\" in GC2N needs to be replaced with GC1N (without the .py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"cp %s deleteMe.py\" %(GC2N))\n",
    "newF = open(GC2N, \"w\")\n",
    "for line in open(\"deleteMe.py\"):\n",
    "    newF.write(line.replace(\"???\", GC1N.replace(\".py\", \"\")))\n",
    "newF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use importlib to import generate code using full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = importlib.util.spec_from_file_location(GC2N.replace(\".py\", \"\") \\\n",
    "                                              , os.path.join(os.getcwd(), GC2N))\n",
    "genClass = importlib.util.module_from_spec(spec) \n",
    "spec.loader.exec_module(genClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data file\n",
    "Now we have a genClass that was made from the code generated from the xsd. Below we use that class to load the data into a structure. We'll watch the time also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab data file\n",
    "# urllib.request.urlretrieve(INFP, INFN)\n",
    "req = requests.get(INFP)\n",
    "inF = open(INFN, \"wb\")\n",
    "inF.write(req.content)\n",
    "inF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:54:57\n",
      "17:55:13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55887"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print (dt.now().strftime(\"%H:%M:%S\"))\n",
    "root = autoSub.parse(INFN, silence=True)\n",
    "print (dt.now().strftime(\"%H:%M:%S\"))\n",
    "len(root.assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing to xml lib\n",
    "Lust looking at one obs to get a feel for what using the xsd to generate code bought us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0001814917 - 000001'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.assets[0].__dict__[\"assetNumber\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeating with xml lib to compare\n",
    "Parsing with xml.etree.ElementTree is about 2x faster (because Python modules are almost always faster than Python), but the names in the structure have garbage in them I just don't want to deal with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:55:30\n",
      "17:55:38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55887"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "print (dt.now().strftime(\"%H:%M:%S\"))\n",
    "tree = ET.parse(INFN)\n",
    "fromXmlLib = tree.getroot()\n",
    "print (dt.now().strftime(\"%H:%M:%S\"))\n",
    "len(fromXmlLib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element '{http://www.sec.gov/edgar/document/absee/autoloan/assetdata}assetNumber' at 0x7ff918646220>\n",
      "0001814917 - 000001\n"
     ]
    }
   ],
   "source": [
    "print (fromXmlLib[0][1])\n",
    "print (fromXmlLib[0][1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to DataFrame\n",
    "Because the parser in the generated code gives the same names as the documentation, we can just use those names to build a dictionary and cast it as a DF. Using an OrderedDict here to give the DF the same order as the docs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55887, 72)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init dict\n",
    "tD = OrderedDict() \n",
    "for field in fmtR.fieldName:\n",
    "    tD[field] = [] # set up list for an element\n",
    "# populate\n",
    "for entry in root.assets:\n",
    "    for field in fmtR.fieldName:\n",
    "        tD[field].append(entry.__dict__[field])\n",
    "# cast as DF\n",
    "tR = pd.DataFrame(tD)\n",
    "tR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists\n",
    "There are a few fields in the Version 1.8 spec that can occur an \"unlimited\" number of times, which was probably a bad idea but the generated parser handles well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0'], [], [], []]\n",
      "[<class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>]\n"
     ]
    }
   ],
   "source": [
    "mnL = \"\"\"subvented zeroBalanceCode repurchaseReplacementReasonCode \n",
    "modificationTypeCode\"\"\".split()\n",
    "mL = [tR.iloc[0][mn] for mn in mnL]\n",
    "print (mL)\n",
    "print (list(map(type, mL)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and Postprocessing\n",
    "The parser has validators, but, since we have the data now loaded into a DF, I prefer to validate there. Because this file has all valid values for the reportingPeriodBeginningDate, we can cast it to a date with a Pandas to_datetime. Validting and casting all 72 fields for all SPE is a bigger exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05-01-2020    55887\n",
      "Name: reportingPeriodBeginningDate, dtype: int64\n",
      "2020-05-01    55887\n",
      "Name: reportingPeriodBeginningDate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (tR.reportingPeriodBeginningDate.value_counts().sort_index())  # before \n",
    "tR.reportingPeriodBeginningDate = pd.to_datetime(tR.reportingPeriodBeginningDate)\n",
    "print (tR.reportingPeriodBeginningDate.value_counts().sort_index()) # after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
